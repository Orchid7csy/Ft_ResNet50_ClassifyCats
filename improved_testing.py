import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import preprocess_input
from PIL import Image
import cv2
import glob
from collections import defaultdict
from image_preprocessing import letterbox_preprocess
from find_real_img import find_cat_with_haar

# è®¾ç½®éšæœºç§å­
tf.random.set_seed(42)
np.random.seed(42)

class ImprovedTester:
    """æ”¹è¿›çš„æµ‹è¯•ç±»"""
    
    def __init__(self, model_path, test_dir, img_size=(224, 224)):
        self.model_path = model_path
        self.test_dir = test_dir
        self.img_size = img_size
        self.class_names = ['Pallas', 'Persian', 'Ragdoll', 'Singapura', 'Sphynx']
        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}
        self.idx_to_class = {idx: name for idx, name in enumerate(self.class_names)}
        
        # åŠ è½½æ¨¡å‹
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        self.model = load_model(model_path)
        print("æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def extract_true_label_from_filename(self, filename):
        """ä»æ–‡ä»¶åæå–çœŸå®æ ‡ç­¾"""
        filename_lower = filename.lower()
        for class_name in self.class_names:
            if class_name.lower() in filename_lower:
                return class_name
        return None
    
    def load_image_with_haar(self, image_path):
        """ä½¿ç”¨Haaræ£€æµ‹åŠ è½½å›¾ç‰‡"""
        try:
            # ä½¿ç”¨OpenCVè¯»å–å›¾åƒ
            cv_image = cv2.imread(image_path)
            if cv_image is None:
                raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
            
            # ä½¿ç”¨Haaræ£€æµ‹çŒ«è„¸
            try:
                cat_faces = find_cat_with_haar(cv_image)
                
                if cat_faces is not None and len(cat_faces) > 0:
                    # æ£€æµ‹åˆ°çŒ«è„¸ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„çŒ«è„¸åŒºåŸŸ
                    x, y, w, h = cat_faces[0]
                    cat_face_roi = cv_image[y:y+h, x:x+w]
                    img = Image.fromarray(cv2.cvtColor(cat_face_roi, cv2.COLOR_BGR2RGB))
                    detection_status = f"Haaræ£€æµ‹åˆ° ({len(cat_faces)} ä¸ªçŒ«è„¸)"
                else:
                    # æ²¡æœ‰æ£€æµ‹åˆ°çŒ«è„¸ï¼Œä½¿ç”¨åŸå›¾
                    img = Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))
                    detection_status = "æœªæ£€æµ‹åˆ°çŒ«è„¸ï¼Œä½¿ç”¨åŸå›¾"
                    
            except Exception as e:
                # å¦‚æœHaaræ£€æµ‹å‡ºé”™ï¼Œä½¿ç”¨åŸå›¾
                print(f"Haaræ£€æµ‹é”™è¯¯ {image_path}: {e}")
                img = Image.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))
                detection_status = "æ£€æµ‹é”™è¯¯ï¼Œä½¿ç”¨åŸå›¾"
            
            # ä½¿ç”¨letterboxingé¢„å¤„ç†
            img_array = np.array(img)
            img_processed = letterbox_preprocess(img_array, self.img_size)
            
            # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
            img_array = np.array(img_processed, dtype=np.float32)
            img_array = np.expand_dims(img_array, axis=0)
            img_array = preprocess_input(img_array)
            
            return img_array, detection_status
            
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return None, f"åŠ è½½å¤±è´¥: {e}"
    
    def load_image_original(self, image_path):
        """åŸå§‹å›¾ç‰‡åŠ è½½æ–¹æ³•"""
        try:
            # ç›´æ¥åŠ è½½å¹¶è°ƒæ•´å¤§å°
            img = Image.open(image_path).convert('RGB')
            
            try:
                resample = Image.Resampling.LANCZOS
            except AttributeError:
                resample = Image.LANCZOS
                
            img = img.resize(self.img_size, resample)
            
            # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
            img_array = np.array(img, dtype=np.float32)
            img_array = np.expand_dims(img_array, axis=0)
            img_array = preprocess_input(img_array)
            
            return img_array
            
        except Exception as e:
            print(f"åŸå§‹æ–¹æ³•åŠ è½½å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return None
    
    def predict_single(self, img_array):
        """å•å¼ å›¾ç‰‡é¢„æµ‹"""
        if img_array is None:
            return None, 0, -1
        
        predictions = self.model.predict(img_array, verbose=0)
        predicted_idx = np.argmax(predictions[0])
        confidence = predictions[0][predicted_idx]
        predicted_class = self.idx_to_class[predicted_idx]
        
        return predicted_class, confidence, predicted_idx
    
    def evaluate_comprehensive(self):
        """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("å¼€å§‹å…¨é¢è¯„ä¼°...")
        print("="*60)
        
        # æ”¶é›†æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        test_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            test_files.extend(glob.glob(os.path.join(self.test_dir, ext)))
        
        if not test_files:
            print(f"åœ¨ {self.test_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            return
        
        print(f"æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
        
        # å­˜å‚¨ç»“æœ
        results = {
            'filename': [],
            'true_label': [],
            'haar_prediction': [],
            'haar_confidence': [],
            'haar_correct': [],
            'original_prediction': [],
            'original_confidence': [],
            'original_correct': [],
            'detection_status': []
        }
        
        # ç»Ÿè®¡å˜é‡
        total_processed = 0
        haar_detections = 0
        haar_correct = 0
        original_correct = 0
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        class_stats = defaultdict(lambda: {'total': 0, 'haar_correct': 0, 'original_correct': 0})
        
        print("\nå¼€å§‹å¤„ç†æµ‹è¯•æ–‡ä»¶...")
        
        for i, file_path in enumerate(test_files):
            filename = os.path.basename(file_path)
            true_label = self.extract_true_label_from_filename(filename)
            
            if true_label is None:
                print(f"è­¦å‘Š: æ— æ³•ä»æ–‡ä»¶åæå–çœŸå®æ ‡ç­¾: {filename}")
                continue
            
            # å¤„ç†è¿›åº¦
            if (i + 1) % 10 == 0:
                print(f"å·²å¤„ç†: {i + 1}/{len(test_files)}")
            
            try:
                # Haaræ–¹æ³•æµ‹è¯•
                img_haar, detection_status = self.load_image_with_haar(file_path)
                haar_pred, haar_conf, _ = self.predict_single(img_haar)
                
                # åŸå§‹æ–¹æ³•æµ‹è¯•
                img_original = self.load_image_original(file_path)
                original_pred, original_conf, _ = self.predict_single(img_original)
                
                # æ›´æ–°ç»Ÿè®¡
                total_processed += 1
                class_stats[true_label]['total'] += 1
                
                if "æ£€æµ‹åˆ°" in detection_status:
                    haar_detections += 1
                
                haar_is_correct = (haar_pred == true_label)
                original_is_correct = (original_pred == true_label)
                
                if haar_is_correct:
                    haar_correct += 1
                    class_stats[true_label]['haar_correct'] += 1
                
                if original_is_correct:
                    original_correct += 1
                    class_stats[true_label]['original_correct'] += 1
                
                # ä¿å­˜ç»“æœ
                results['filename'].append(filename)
                results['true_label'].append(true_label)
                results['haar_prediction'].append(haar_pred)
                results['haar_confidence'].append(haar_conf)
                results['haar_correct'].append(haar_is_correct)
                results['original_prediction'].append(original_pred)
                results['original_confidence'].append(original_conf)
                results['original_correct'].append(original_is_correct)
                results['detection_status'].append(detection_status)
                
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {filename}: {e}")
                continue
        
        # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
        if total_processed > 0:
            haar_accuracy = haar_correct / total_processed
            original_accuracy = original_correct / total_processed
            detection_rate = haar_detections / total_processed
            
            # æ‰“å°ç»“æœ
            print(f"\n{'='*60}")
            print("è¯„ä¼°ç»“æœæ±‡æ€»:")
            print(f"{'='*60}")
            print(f"æ€»å¤„ç†æ–‡ä»¶æ•°: {total_processed}")
            print(f"Haaræ£€æµ‹æˆåŠŸç‡: {haar_detections} ({detection_rate*100:.1f}%)")
            print(f"")
            print(f"Haaræ–¹æ³•å‡†ç¡®ç‡: {haar_correct}/{total_processed} = {haar_accuracy:.3f} ({haar_accuracy*100:.1f}%)")
            print(f"åŸå§‹æ–¹æ³•å‡†ç¡®ç‡: {original_correct}/{total_processed} = {original_accuracy:.3f} ({original_accuracy*100:.1f}%)")
            
            if haar_accuracy > original_accuracy:
                improvement = (haar_accuracy - original_accuracy) * 100
                print(f"ğŸ‰ Haaræ–¹æ³•å‡†ç¡®ç‡æå‡ {improvement:.1f} ä¸ªç™¾åˆ†ç‚¹!")
            elif haar_accuracy < original_accuracy:
                decline = (original_accuracy - haar_accuracy) * 100
                print(f"âš ï¸  Haaræ–¹æ³•å‡†ç¡®ç‡ä¸‹é™ {decline:.1f} ä¸ªç™¾åˆ†ç‚¹")
            else:
                print("ğŸ“Š ä¸¤ç§æ–¹æ³•å‡†ç¡®ç‡ç›¸åŒ")
            
            # æ‰“å°å„ç±»åˆ«è¯¦ç»†ç»“æœ
            print(f"\n{'='*60}")
            print("å„ç±»åˆ«è¯¦ç»†ç»“æœ:")
            print(f"{'='*60}")
            print(f"{'ç±»åˆ«':>10} {'æ ·æœ¬æ•°':>8} {'Haarå‡†ç¡®ç‡':>12} {'åŸå§‹å‡†ç¡®ç‡':>12} {'å·®å¼‚':>10}")
            print("-" * 60)
            
            for class_name in self.class_names:
                stats = class_stats[class_name]
                total = stats['total']
                if total > 0:
                    haar_acc = stats['haar_correct'] / total
                    original_acc = stats['original_correct'] / total
                    diff = (haar_acc - original_acc) * 100
                    print(f"{class_name:>10} {total:>8} {haar_acc*100:>11.1f}% {original_acc*100:>11.1f}% {diff:>+9.1f}%")
                else:
                    print(f"{class_name:>10} {'æ— æ ·æœ¬':>8}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
        results_df = pd.DataFrame(results)
        results_df.to_csv('evaluation_results.csv', index=False)
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: evaluation_results.csv")
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.generate_visualizations(results_df, class_stats)
        
        return results_df, class_stats
    
    def generate_visualizations(self, results_df, class_stats):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Model Evaluation Results', fontsize=16)
        
        # 1. æ•´ä½“å‡†ç¡®ç‡å¯¹æ¯”
        methods = ['Haar Method', 'Original Method']
        haar_acc = results_df['haar_correct'].mean()
        original_acc = results_df['original_correct'].mean()
        accuracies = [haar_acc, original_acc]
        
        bars1 = axes[0, 0].bar(methods, accuracies, color=['skyblue', 'lightcoral'])
        axes[0, 0].set_title('Overall Accuracy Comparison')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].set_ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars1, accuracies):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                           f'{acc:.3f}', ha='center', va='bottom')
        
        # 2. å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”
        class_names = []
        haar_accs = []
        original_accs = []
        
        for class_name in self.class_names:
            stats = class_stats[class_name]
            if stats['total'] > 0:
                class_names.append(class_name)
                haar_accs.append(stats['haar_correct'] / stats['total'])
                original_accs.append(stats['original_correct'] / stats['total'])
        
        x = np.arange(len(class_names))
        width = 0.35
        
        bars2 = axes[0, 1].bar(x - width/2, haar_accs, width, label='Haar Method', color='skyblue')
        bars3 = axes[0, 1].bar(x + width/2, original_accs, width, label='Original Method', color='lightcoral')
        
        axes[0, 1].set_title('Per-Class Accuracy Comparison')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].set_xlabel('Cat Breed')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(class_names, rotation=45)
        axes[0, 1].legend()
        axes[0, 1].set_ylim(0, 1)
        
        # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
        axes[1, 0].hist(results_df['haar_confidence'], bins=20, alpha=0.7, label='Haar Method', color='skyblue')
        axes[1, 0].hist(results_df['original_confidence'], bins=20, alpha=0.7, label='Original Method', color='lightcoral')
        axes[1, 0].set_title('Confidence Distribution')
        axes[1, 0].set_xlabel('Confidence')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].legend()
        
        # 4. æ··æ·†çŸ©é˜µ (Haaræ–¹æ³•)
        true_labels = [self.class_to_idx[label] for label in results_df['true_label']]
        haar_preds = [self.class_to_idx[pred] for pred in results_df['haar_prediction']]
        
        cm = confusion_matrix(true_labels, haar_preds)
        im = axes[1, 1].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        axes[1, 1].set_title('Confusion Matrix (Haar Method)')
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im, ax=axes[1, 1])
        
        # æ·»åŠ æ ‡ç­¾
        tick_marks = np.arange(len(self.class_names))
        axes[1, 1].set_xticks(tick_marks)
        axes[1, 1].set_yticks(tick_marks)
        axes[1, 1].set_xticklabels(self.class_names, rotation=45)
        axes[1, 1].set_yticklabels(self.class_names)
        
        # æ·»åŠ æ•°å€¼
        thresh = cm.max() / 2.
        for i, j in np.ndindex(cm.shape):
            axes[1, 1].text(j, i, format(cm[i, j], 'd'),
                           ha="center", va="center",
                           color="white" if cm[i, j] > thresh else "black")
        
        axes[1, 1].set_ylabel('True Label')
        axes[1, 1].set_xlabel('Predicted Label')
        
        plt.tight_layout()
        plt.savefig('evaluation_visualizations.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: evaluation_visualizations.png")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        'cats_improved_final.keras',
        'cats.keras',
        'best_model_fold_1.keras'
    ]
    
    model_path = None
    for model_file in model_files:
        if os.path.exists(model_file):
            model_path = model_file
            break
    
    if model_path is None:
        print("é”™è¯¯: æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
        print("è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨:")
        for model_file in model_files:
            print(f"  - {model_file}")
        return
    
    # æµ‹è¯•ç›®å½•
    test_dir = './test_samples'
    if not os.path.exists(test_dir):
        print(f"é”™è¯¯: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return
    
    print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
    print(f"æµ‹è¯•ç›®å½•: {test_dir}")
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œè¯„ä¼°
    tester = ImprovedTester(model_path, test_dir)
    results_df, class_stats = tester.evaluate_comprehensive()
    
    print("\nè¯„ä¼°å®Œæˆ!")

if __name__ == "__main__":
    main()